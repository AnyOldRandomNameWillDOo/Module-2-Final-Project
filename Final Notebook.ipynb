{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Module 2 Final Project Submission\n",
    "* Name: Vivienne DiFrancesco\n",
    "* Pace: Full Time\n",
    "* Instructor: James Irving"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Obtaining the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.200604Z",
     "start_time": "2020-09-02T03:33:56.313614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Importing libraries that I will use\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.ticker as mtick\n",
    "%matplotlib inline\n",
    "\n",
    "# Setting default seaborn setting for my visuals\n",
    "sns.set(style=\"whitegrid\")\n",
    "\n",
    "# Supressing warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing the statsmodels packages I will use\n",
    "import statsmodels.formula.api as smf\n",
    "import statsmodels.api as sm\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "\n",
    "# Importing scikit learn packages I will use\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_squared_error, make_scorer\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.204607Z",
     "start_time": "2020-09-02T03:33:58.201616Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting pandas to display max columns and rows\n",
    "pd.set_option('display.max_columns', 0)\n",
    "pd.set_option('display.max_rows', None)\n",
    "\n",
    "# Turning off scientific notation in pandas\n",
    "pd.set_option('display.float_format', lambda x: '%.3f' % x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.332698Z",
     "start_time": "2020-09-02T03:33:58.206605Z"
    }
   },
   "outputs": [],
   "source": [
    "# Loading in the data\n",
    "df = pd.read_csv('kc_house_data.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When I attempted to set the index I used the verify_integrity=True parameter and got an error that there were duplicate keys. That is how I knew that there were houses that had been sold multiple times in the dataset. I saved those duplicate items as their own dataframe to be able to return to later for EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.369602Z",
     "start_time": "2020-09-02T03:33:58.334602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making a new dataframe to look at later of houses sold multiple times\n",
    "houses_resold = df[df.duplicated(keep=False, subset=['id'])]\n",
    "houses_resold.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.377601Z",
     "start_time": "2020-09-02T03:33:58.371602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Set the index to the id\n",
    "df.set_index('id', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.386606Z",
     "start_time": "2020-09-02T03:33:58.380614Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking out the length and columns\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.401602Z",
     "start_time": "2020-09-02T03:33:58.387601Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the data types and where there might be nulls\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scrub"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Addressing the price column"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I started with the price column since that is the target. I wanted to get to know the data a little using describe(). I looked at value_counts() to make sure there weren't issues with rogue values like 0000 or something that would not register as nulls."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.408602Z",
     "start_time": "2020-09-02T03:33:58.403600Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making price an integer instead of a float\n",
    "df.price = df.price.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.419601Z",
     "start_time": "2020-09-02T03:33:58.410602Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the stats for the column to see if everything looks normal\n",
    "df.price.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.428600Z",
     "start_time": "2020-09-02T03:33:58.421603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Double checking that there aren't rogue values hiding in the data\n",
    "df.price.value_counts()[:20]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dealing with NA values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I then turned to the other columns to deal with NA values. I filled the NA values, cast them to the correct data type, and then used value_counts() to check for rogue entries that may have been missed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.443606Z",
     "start_time": "2020-09-02T03:33:58.430603Z"
    }
   },
   "outputs": [],
   "source": [
    "# Looking at all NA values in all columns\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I tried mapping the entries that were missing waterfront and it seems as if some of the values are in fact on the water. I decided to fill the null values based on the ratio of 0 and 1 that are already in the dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:38:54.881145Z",
     "start_time": "2020-09-02T03:38:54.873127Z"
    }
   },
   "outputs": [],
   "source": [
    "# Creating a sub-dataframe of the missing entries to use for visualizing\n",
    "waterfront_check = df.copy()\n",
    "waterfront_check = waterfront_check[waterfront_check['waterfront'].isna()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T01:44:53.928837Z",
     "start_time": "2020-09-02T01:44:53.873849Z"
    }
   },
   "outputs": [],
   "source": [
    "# Saving the file\n",
    "\n",
    "# waterfront_check.to_csv(r'C:\\Users\\drudi\\DataScience\\Module02\\FinalProject\\waterfront_check.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This map was created using the waterfront_check dataframe loaded into Tableau Public. This screenshot is a zoomed in view to better see individual entries as an example. The full image can be viewed and downloaded from https://public.tableau.com/profile/vivienne4370 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:56:44.344887Z",
     "start_time": "2020-09-02T03:56:44.339888Z"
    }
   },
   "source": [
    "<img src=\"waterfrontcheck.png\">"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.456600Z",
     "start_time": "2020-09-02T03:33:58.444599Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking the percentages of the different values\n",
    "df.waterfront.value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:33:58.463600Z",
     "start_time": "2020-09-02T03:33:58.457598Z"
    }
   },
   "outputs": [],
   "source": [
    "# Checking value counts before filling the missing values\n",
    "df.waterfront.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:34:24.631247Z",
     "start_time": "2020-09-02T03:34:24.550212Z"
    }
   },
   "outputs": [],
   "source": [
    "# Setting the probability ratios based on the value counts\n",
    "prob = [.992, .008]\n",
    "\n",
    "# Filling the missing values with either 0 or 1 using the probability\n",
    "df[\"waterfront\"] = df[\"waterfront\"].apply(lambda x: np.random.choice([0, 1], p=prob) if (np.isnan(x)) else x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-09-02T03:34:34.196959Z",
     "start_time": "2020-09-02T03:34:34.184981Z"
    }
   },
   "outputs": [],
   "source": [
    "# Making sure the value counts changed appropriately\n",
    "df[\"waterfront\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the datatype\n",
    "df.waterfront = df.waterfront.astype('int64')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I dropped the view column since it is not clear what this data represents. It does not represent the views from the house but likely has something to do with listing views. Without knowing what it could mean, I dropped it to avoid any confusion from the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NA values with 0\n",
    "df.drop(columns='view', inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to fill the yr_renovated columns with zeros because I thought it was a fair assumption that if the entry is null, then it probably hasn't been renovated. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filling NA values with 0\n",
    "df.yr_renovated.fillna(0, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Checking for rogue values\n",
    "df.yr_renovated.value_counts()[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Changing the datatype\n",
    "df.yr_renovated = df.yr_renovated.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying that all NAs were dealt with\n",
    "df.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Checking for strange values in other columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I looked through the rest of my columns for rogue entries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "learn-env",
   "language": "python",
   "name": "learn-env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": true
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
